import argparse
import base64
import hashlib
import io
import os

import pymupdf
from PIL import Image

from ai_scientist.llm import create_client
from ai_scientist.tools.llm_review import load_paper


# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def get_image_hash(image):
    # Calculate hash of the image data
    return hashlib.md5(image.tobytes()).hexdigest()


def detect_duplicate_figures(
    png_images,
    duplicate_threshold=0.9,  # This threshold might need tuning for non-exact duplicates
):
    unique_images = []
    hashes = set()

    for i, img in enumerate(png_images):
        # Resize image to small fixed size for hash comparison (optional but robust)
        # img_resized = img.resize((100, 100), Image.ANTIALIAS)
        img_hash = get_image_hash(img)

        if img_hash not in hashes:
            hashes.add(img_hash)
            unique_images.append(i)
        else:
            print(f"Duplicate image detected at index {i}, skipping.")

    return unique_images


def extract_figure_screenshots(pdf_path, temp_dir="temp_figures"):
    doc = pymupdf.open(pdf_path)
    os.makedirs(temp_dir, exist_ok=True)
    png_images = []
    # Identify pages with figures and extract them
    # For now, we'll extract complete pages as screenshots from the PDF
    # and let the VLM decide which parts are figures.
    for i, page in enumerate(doc):
        # Render page to an image
        pix = page.get_pixmap(dpi=150)
        img_data = pix.tobytes("png")
        image = Image.open(io.BytesIO(img_data))
        png_images.append(image)

    unique_indices = detect_duplicate_figures(png_images)
    png_images = [png_images[i] for i in unique_indices]

    return png_images


def generate_vlm_img_review(
    client, model, png_images, metrics_text, research_idea_text, topic_text="machnie learning"
):
    # Prepare the prompt with text context and images
    system_prompt = f"""
You are a Computer Vision and {topic_text} researcher. You are reviewing a paper submitted to a top-tier {topic_text} conference.
You will be provided with screenshots of the paper's figures.
Your goal is to evaluate the quality of the figures and the coherence of the results presented in them.
"""
    prompt = f"""
Below are the experimental results and the research idea of the paper.
Note that the results are obtained from the code execution, so they are accurate.
However, the figures are generated by the author, so they might not be accurate or clear.

Experimental results:
{metrics_text}

Research idea:
{research_idea_text}

Please review the figures and provide feedback.
Focus on the following aspects:
1. Are the figures clear and easy to read?
2. Do the figures accurately represent the experimental results?
3. Are there any figures that are confusing or misleading?
4. Are there any missing comparisons or baselines?
5. Are the axes labeled correctly?
6. Are the legends clear and informative?
7. Suggest improvements for the figures to make them better.
"""

    # Construct the message payload
    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
            ],
        },
    ]

    for img in png_images:
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        messages[1]["content"].append(
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{img_str}"},
            }
        )

    # Call the VLM
    response = client.chat.completions.create(
        model=model, messages=messages, max_tokens=2000, temperature=0.7
    )

    review = response.choices[0].message.content
    return review


def generate_vlm_img_cap_ref_review(
    client,
    model,
    png_images,
    text,
    topic_text="machnie learning",
):
    # Prepare the prompt with text context and images
    system_prompt = f"""
You are a Computer Vision and {topic_text} researcher. You are reviewing a paper submitted to a top-tier {topic_text} conference.
You will be provided with screenshots of the paper's figures and the full text of the paper.
Your goal is to evaluate the quality of the figures and checks if the figures are correctly referenced in the text and vice versa.
"""
    prompt = f"""
Below is the full text of the paper.

Full text:
{text}

Please review the figures and their references in the text.
Answer the following questions:
1. Are all figures referenced in the text?
2. Do the figure captions accurately describe the figures?
3. Are the figure references in the text consistent with the figure numbers?
4. Does the text clearly explain the figures?
5. Suggest improvements for the figure captions and references.
"""

    # Construct the message payload
    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
            ],
        },
    ]

    for img in png_images:
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        messages[1]["content"].append(
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{img_str}"},
            }
        )

    # Call the VLM
    response = client.chat.completions.create(
        model=model, messages=messages, max_tokens=2000, temperature=0.7
    )

    review = response.choices[0].message.content
    return review


def generate_vlm_img_selection_review(
    client,
    model,
    png_images,
    metrics_text,
    research_idea_text,
    topic_text="machnie learning",
):
    # Prepare the prompt with text context and images
    system_prompt = f"""
You are a Computer Vision and {topic_text} researcher. You are reviewing a paper submitted to a top-tier {topic_text} conference.
You will be provided with screenshots of the paper's figures.
Your goal is to select the best figures to include in the paper and the appendix.
"""
    prompt = f"""
Below are the experimental results and the research idea of the paper.
Note that the results are obtained from the code execution, so they are accurate.
However, the figures are generated by the author using code that might not be perfect.
There might be duplicate figures (or very similar ones), or figures that are not clear or informative or plain wrong.

Experimental results:
{metrics_text}

Research idea:
{research_idea_text}

Please review the figures AND the research idea and select the best figures to include in the paper.
We want 1 or 2 figures for the main paper and at most 3 figures for the appendix.
Your task is to provide a list of indices of the figures to include in the paper and the appendix.
The indices should be 0-based and correspond to the order of the figures provided.
Also describe the figures and explain why you selected them.
Try to make the selected figures diverse and informative (e.g. results, ablation studies, different metrics, etc.).
Also suggest where to place the figures (main paper or appendix).

Respond in the following format:
SELECTED FIGURES:
[index1, index2, ...]

REASONING:
<Explain why you selected these figures and where to place them.>
"""

    # Construct the message payload
    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
            ],
        },
    ]

    for img in png_images:
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        messages[1]["content"].append(
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{img_str}"},
            }
        )

    # Call the VLM
    response = client.chat.completions.create(
        model=model, messages=messages, max_tokens=2000, temperature=0.7
    )

    review = response.choices[0].message.content
    return review


def perform_imgs_review(
    pdf_path,
    model,
    client,
    metrics_text,
    research_idea_text,
    topic_text="machine learning",
):
    png_images = extract_figure_screenshots(pdf_path)
    return generate_vlm_img_review(
        client, model, png_images, metrics_text, research_idea_text, topic_text
    )


def perform_imgs_cap_ref_review(pdf_path, model, client, topic_text="machine learning"):
    png_images = extract_figure_screenshots(pdf_path)
    text = load_paper(pdf_path)
    return generate_vlm_img_cap_ref_review(
        client, model, png_images, text, topic_text
    )


def perform_imgs_cap_ref_review_selection(
    image_paths, model, client, metrics_text, research_idea_text, topic_text="machine learning"
):
    png_images = []
    for image_path in image_paths:
        image = Image.open(image_path)
        png_images.append(image)
    return generate_vlm_img_selection_review(
        client, model, png_images, metrics_text, research_idea_text, topic_text
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--pdf-path", type=str, required=True, help="Path to the PDF file to review"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-4o-2024-05-13",
        help="Model to use for VLM review",
    )
    args = parser.parse_args()

    client, model = create_client(args.model)

    print(perform_imgs_review(args.pdf_path, model, client, "", ""))
    print(perform_imgs_cap_ref_review(args.pdf_path, model, client))
